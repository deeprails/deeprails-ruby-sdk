# typed: strong

module Deeprails
  module Resources
    class Defend
      # Create a new guardrail workflow with optional guardrail thresholds and
      # improvement actions.
      sig do
        params(
          improvement_action:
            T.nilable(
              Deeprails::DefendCreateWorkflowParams::ImprovementAction::OrSymbol
            ),
          metrics: T::Hash[Symbol, Float],
          name: String,
          type: Deeprails::DefendCreateWorkflowParams::Type::OrSymbol,
          automatic_tolerance:
            Deeprails::DefendCreateWorkflowParams::AutomaticTolerance::OrSymbol,
          description: String,
          max_retries: Integer,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def create_workflow(
        # The action used to improve outputs that fail one or guardrail metrics for the
        # workflow events. May be `regenerate`, `fixit`, or null which represents “do
        # nothing”. ReGen runs the user's exact input prompt with minor induced variance.
        # Fixit attempts to directly address the shortcomings of the output using the
        # guardrail failure rationale. Do nothing does not attempt any improvement.
        improvement_action:,
        # Mapping of guardrail metrics to floating point threshold values. If the workflow
        # type is automatic, only the metric names are used (`automatic_tolerance`
        # determines thresholds). Possible metrics are `correctness`, `completeness`,
        # `instruction_adherence`, `context_adherence`, `ground_truth_adherence`, or
        # `comprehensive_safety`.
        metrics:,
        # Name of the workflow.
        name:,
        # Type of thresholds to use for the workflow, either `automatic` or `custom`.
        # Automatic thresholds are assigned internally after the user specifies a
        # qualitative tolerance for the metrics, whereas custom metrics allow the user to
        # set the threshold for each metric as a floating point number between 0.0 and
        # 1.0.
        type:,
        # Hallucination tolerance for automatic workflows; may be `low`, `medium`, or
        # `high`. Ignored if `type` is `custom`.
        automatic_tolerance: nil,
        # Description for the workflow.
        description: nil,
        # Max. number of improvement action retries until a given event passes the
        # guardrails. Defaults to 10.
        max_retries: nil,
        request_options: {}
      )
      end

      # Retrieve a specific event of a guardrail workflow.
      sig do
        params(
          event_id: String,
          workflow_id: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::WorkflowEventResponse)
      end
      def retrieve_event(
        # The ID of the requested workflow event.
        event_id,
        # The ID of the workflow associated with the event.
        workflow_id:,
        request_options: {}
      )
      end

      # Retrieve the details for a specific guardrail workflow.
      sig do
        params(
          workflow_id: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def retrieve_workflow(
        # The ID of the workflow to retrieve.
        workflow_id,
        request_options: {}
      )
      end

      # Submit a model input and output pair to a workflow for evaluation.
      sig do
        params(
          workflow_id: String,
          model_input: Deeprails::DefendSubmitEventParams::ModelInput::OrHash,
          model_output: String,
          model_used: String,
          nametag: String,
          run_mode: Deeprails::DefendSubmitEventParams::RunMode::OrSymbol,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::WorkflowEventResponse)
      end
      def submit_event(
        # Workflow ID associated with this event.
        workflow_id,
        # A dictionary of inputs sent to the LLM to generate output. This must contain a
        # `user_prompt` field and an optional `context` field. Additional properties are
        # allowed.
        model_input:,
        # Output generated by the LLM to be evaluated.
        model_output:,
        # Model ID used to generate the output, like `gpt-4o` or `o3`.
        model_used:,
        # An optional, user-defined tag for the event.
        nametag:,
        # Run mode for the workflow event. The run mode allows the user to optimize for
        # speed, accuracy, and cost by determining which models are used to evaluate the
        # event. Available run modes include `precision_plus`, `precision`, `smart`, and
        # `economy`. Defaults to `smart`.
        run_mode:,
        request_options: {}
      )
      end

      # Update an existing guardrail workflow.
      sig do
        params(
          workflow_id: String,
          description: String,
          name: String,
          type: Deeprails::DefendUpdateWorkflowParams::Type::OrSymbol,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def update_workflow(
        # The ID of the workflow to edit.
        workflow_id,
        # Description for the workflow.
        description: nil,
        # Name of the workflow.
        name: nil,
        # Type of thresholds to use for the workflow, either `automatic` or `custom`.
        type: nil,
        request_options: {}
      )
      end

      # @api private
      sig { params(client: Deeprails::Client).returns(T.attached_class) }
      def self.new(client:)
      end
    end
  end
end
