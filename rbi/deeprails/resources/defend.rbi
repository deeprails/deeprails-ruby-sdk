# typed: strong

module Deeprails
  module Resources
    class Defend
      # Use this endpoint to create a new guardrail workflow with optional guardrail
      # thresholds and improvement actions
      sig do
        params(
          improvement_action:
            Deeprails::DefendCreateWorkflowParams::ImprovementAction::OrSymbol,
          name: String,
          type: Deeprails::DefendCreateWorkflowParams::Type::OrSymbol,
          automatic_hallucination_tolerance_levels:
            T::Hash[
              Symbol,
              Deeprails::DefendCreateWorkflowParams::AutomaticHallucinationToleranceLevel::OrSymbol
            ],
          custom_hallucination_threshold_values: T::Hash[Symbol, Float],
          description: String,
          max_improvement_attempt: Integer,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def create_workflow(
        # The action used to improve outputs that fail one or guardrail metrics for the
        # workflow events. May be `regen`, `fixit`, or `do_nothing`. ReGen runs the user's
        # input prompt with minor induced variance. FixIt attempts to directly address the
        # shortcomings of the output using the guardrail failure rationale. Do Nothing
        # does not attempt any improvement.
        improvement_action:,
        # Name of the workflow.
        name:,
        # Type of thresholds to use for the workflow, either `automatic` or `custom`.
        # Automatic thresholds are assigned internally after the user specifies a
        # qualitative tolerance for the metrics, whereas custom metrics allow the user to
        # set the threshold for each metric as a floating point number between 0.0 and
        # 1.0.
        type:,
        # Mapping of guardrail metrics to hallucination tolerance levels (either `low`,
        # `medium`, or `high`). Possible metrics are `completeness`,
        # `instruction_adherence`, `context_adherence`, `ground_truth_adherence`, or
        # `comprehensive_safety`.
        automatic_hallucination_tolerance_levels: nil,
        # Mapping of guardrail metrics to floating point threshold values. Possible
        # metrics are `correctness`, `completeness`, `instruction_adherence`,
        # `context_adherence`, `ground_truth_adherence`, or `comprehensive_safety`.
        custom_hallucination_threshold_values: nil,
        # Description for the workflow.
        description: nil,
        # Max. number of improvement action retries until a given event passes the
        # guardrails. Defaults to 10.
        max_improvement_attempt: nil,
        request_options: {}
      )
      end

      # Use this endpoint to retrieve a specific event of a guardrail workflow
      sig do
        params(
          event_id: String,
          workflow_id: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::WorkflowEventResponse)
      end
      def retrieve_event(
        # The ID of the requested workflow event.
        event_id,
        # The ID of the workflow associated with the event.
        workflow_id:,
        request_options: {}
      )
      end

      # Use this endpoint to retrieve the details for a specific defend workflow
      sig do
        params(
          workflow_id: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def retrieve_workflow(
        # The ID of the workflow to retrieve.
        workflow_id,
        request_options: {}
      )
      end

      # Use this endpoint to submit a model input and output pair to a workflow for
      # evaluation
      sig do
        params(
          workflow_id: String,
          model_input: Deeprails::DefendSubmitEventParams::ModelInput::OrHash,
          model_output: String,
          model_used: String,
          run_mode: Deeprails::DefendSubmitEventParams::RunMode::OrSymbol,
          nametag: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::WorkflowEventResponse)
      end
      def submit_event(
        # Workflow ID associated with this event.
        workflow_id,
        # A dictionary of inputs sent to the LLM to generate output. The dictionary must
        # contain at least `user_prompt` or `system_prompt` field. For the
        # ground_truth_adherence guardrail metric, `ground_truth` should be provided.
        model_input:,
        # Output generated by the LLM to be evaluated.
        model_output:,
        # Model ID used to generate the output, like `gpt-4o` or `o3`.
        model_used:,
        # Run mode for the workflow event. The run mode allows the user to optimize for
        # speed, accuracy, and cost by determining which models are used to evaluate the
        # event. Available run modes include `precision_plus`, `precision`, `smart`, and
        # `economy`. Defaults to `smart`.
        run_mode:,
        # An optional, user-defined tag for the event.
        nametag: nil,
        request_options: {}
      )
      end

      # Use this endpoint to update an existing guardrail workflow
      sig do
        params(
          workflow_id: String,
          description: String,
          name: String,
          request_options: Deeprails::RequestOptions::OrHash
        ).returns(Deeprails::DefendResponse)
      end
      def update_workflow(
        # The ID of the workflow to edit.
        workflow_id,
        # Description for the workflow.
        description: nil,
        # Name of the workflow.
        name: nil,
        request_options: {}
      )
      end

      # @api private
      sig { params(client: Deeprails::Client).returns(T.attached_class) }
      def self.new(client:)
      end
    end
  end
end
