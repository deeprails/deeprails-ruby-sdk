# frozen_string_literal: true

module Deeprails
  module Models
    # @see Deeprails::Resources::Evaluate#create
    class EvaluateCreateParams < Deeprails::Internal::Type::BaseModel
      extend Deeprails::Internal::Type::RequestParameters::Converter
      include Deeprails::Internal::Type::RequestParameters

      # @!attribute model_input
      #   A dictionary of inputs sent to the LLM to generate output. The dictionary must
      #   contain at least `user_prompt` or `system_prompt` field. For
      #   ground_truth_adherence guardrail metric, `ground_truth` should be provided.
      #
      #   @return [Deeprails::Models::EvaluateCreateParams::ModelInput]
      required :model_input, -> { Deeprails::EvaluateCreateParams::ModelInput }

      # @!attribute model_output
      #   Output generated by the LLM to be evaluated.
      #
      #   @return [String]
      required :model_output, String

      # @!attribute run_mode
      #   Run mode for the evaluation. The run mode allows the user to optimize for speed,
      #   accuracy, and cost by determining which models are used to evaluate the event.
      #   Available run modes include `precision_plus`, `precision`, `smart`, and
      #   `economy`. Defaults to `smart`.
      #
      #   @return [Symbol, Deeprails::Models::EvaluateCreateParams::RunMode]
      required :run_mode, enum: -> { Deeprails::EvaluateCreateParams::RunMode }

      # @!attribute guardrail_metrics
      #   An array of guardrail metrics that the model input and output pair will be
      #   evaluated on. For non-enterprise users, these will be limited to the allowed
      #   guardrail metrics.
      #
      #   @return [Array<Symbol, Deeprails::Models::EvaluateCreateParams::GuardrailMetric>, nil]
      optional :guardrail_metrics,
               -> { Deeprails::Internal::Type::ArrayOf[enum: Deeprails::EvaluateCreateParams::GuardrailMetric] }

      # @!attribute model_used
      #   Model ID used to generate the output, like `gpt-4o` or `o3`.
      #
      #   @return [String, nil]
      optional :model_used, String

      # @!attribute nametag
      #   An optional, user-defined tag for the evaluation.
      #
      #   @return [String, nil]
      optional :nametag, String

      # @!method initialize(model_input:, model_output:, run_mode:, guardrail_metrics: nil, model_used: nil, nametag: nil, request_options: {})
      #   Some parameter documentations has been truncated, see
      #   {Deeprails::Models::EvaluateCreateParams} for more details.
      #
      #   @param model_input [Deeprails::Models::EvaluateCreateParams::ModelInput] A dictionary of inputs sent to the LLM to generate output. The dictionary must c
      #
      #   @param model_output [String] Output generated by the LLM to be evaluated.
      #
      #   @param run_mode [Symbol, Deeprails::Models::EvaluateCreateParams::RunMode] Run mode for the evaluation. The run mode allows the user to optimize for speed
      #
      #   @param guardrail_metrics [Array<Symbol, Deeprails::Models::EvaluateCreateParams::GuardrailMetric>] An array of guardrail metrics that the model input and output pair will be evalu
      #
      #   @param model_used [String] Model ID used to generate the output, like `gpt-4o` or `o3`.
      #
      #   @param nametag [String] An optional, user-defined tag for the evaluation.
      #
      #   @param request_options [Deeprails::RequestOptions, Hash{Symbol=>Object}]

      class ModelInput < Deeprails::Internal::Type::BaseModel
        # @!attribute ground_truth
        #   The ground truth for evaluating Ground Truth Adherence guardrail.
        #
        #   @return [String, nil]
        optional :ground_truth, String

        # @!attribute system_prompt
        #   The system prompt used to generate the output.
        #
        #   @return [String, nil]
        optional :system_prompt, String

        # @!attribute user_prompt
        #   The user prompt used to generate the output.
        #
        #   @return [String, nil]
        optional :user_prompt, String

        # @!method initialize(ground_truth: nil, system_prompt: nil, user_prompt: nil)
        #   A dictionary of inputs sent to the LLM to generate output. The dictionary must
        #   contain at least `user_prompt` or `system_prompt` field. For
        #   ground_truth_adherence guardrail metric, `ground_truth` should be provided.
        #
        #   @param ground_truth [String] The ground truth for evaluating Ground Truth Adherence guardrail.
        #
        #   @param system_prompt [String] The system prompt used to generate the output.
        #
        #   @param user_prompt [String] The user prompt used to generate the output.
      end

      # Run mode for the evaluation. The run mode allows the user to optimize for speed,
      # accuracy, and cost by determining which models are used to evaluate the event.
      # Available run modes include `precision_plus`, `precision`, `smart`, and
      # `economy`. Defaults to `smart`.
      module RunMode
        extend Deeprails::Internal::Type::Enum

        PRECISION_PLUS = :precision_plus
        PRECISION = :precision
        SMART = :smart
        ECONOMY = :economy

        # @!method self.values
        #   @return [Array<Symbol>]
      end

      module GuardrailMetric
        extend Deeprails::Internal::Type::Enum

        CORRECTNESS = :correctness
        COMPLETENESS = :completeness
        INSTRUCTION_ADHERENCE = :instruction_adherence
        CONTEXT_ADHERENCE = :context_adherence
        GROUND_TRUTH_ADHERENCE = :ground_truth_adherence
        COMPREHENSIVE_SAFETY = :comprehensive_safety

        # @!method self.values
        #   @return [Array<Symbol>]
      end
    end
  end
end
